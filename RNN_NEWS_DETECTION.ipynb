{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\leonayu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\leonayu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\spacy\\util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.0) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.2). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\leonayu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\spacy\\util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.0) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.2). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import numpy as np \n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import spacy\n",
    "import re\n",
    "import nltk, string\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob, Word\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import hstack, vstack\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import learning_curve, StratifiedShuffleSplit, StratifiedKFold, ShuffleSplit\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import recall_score, accuracy_score, f1_score\n",
    "#load stopwords corpus\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "#load the en_core_web_sm \n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CBS_NEWS=pd.read_csv(r\"C:\\\\Users\\\\leonayu\\\\Documents\\\\Zhuohan\\\\725\\\\2nd_semester\\\\data\\\\cbs_news_content.csv\",header=None)\n",
    "CBS_NEWS.columns=['link',\"title\",\"Author\",\"timestamp\",\"Paragraph_num\",\"Paragraph_text\",\"download_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>Author</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Paragraph_num</th>\n",
       "      <th>Paragraph_text</th>\n",
       "      <th>download_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.cbsnews.com/news/antares-rocket-bo...</td>\n",
       "      <td>Northrop Grumman Antares rocket boosts space s...</td>\n",
       "      <td>WILLIAM HARWOOD</td>\n",
       "      <td>2/15/2020 16:26</td>\n",
       "      <td>0</td>\n",
       "      <td>Running nearly a week late, a Northrop Grumman...</td>\n",
       "      <td>2/17/2020 21:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.cbsnews.com/news/antares-rocket-bo...</td>\n",
       "      <td>Northrop Grumman Antares rocket boosts space s...</td>\n",
       "      <td>WILLIAM HARWOOD</td>\n",
       "      <td>2/15/2020 16:26</td>\n",
       "      <td>1</td>\n",
       "      <td>The rocket's Russian-built RD-181 first stage ...</td>\n",
       "      <td>2/17/2020 21:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://www.cbsnews.com/news/antares-rocket-bo...   \n",
       "1  https://www.cbsnews.com/news/antares-rocket-bo...   \n",
       "\n",
       "                                               title           Author  \\\n",
       "0  Northrop Grumman Antares rocket boosts space s...  WILLIAM HARWOOD   \n",
       "1  Northrop Grumman Antares rocket boosts space s...  WILLIAM HARWOOD   \n",
       "\n",
       "         timestamp  Paragraph_num  \\\n",
       "0  2/15/2020 16:26              0   \n",
       "1  2/15/2020 16:26              1   \n",
       "\n",
       "                                      Paragraph_text    download_date  \n",
       "0  Running nearly a week late, a Northrop Grumman...  2/17/2020 21:19  \n",
       "1  The rocket's Russian-built RD-181 first stage ...  2/17/2020 21:19  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CBS_NEWS.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a stop words list\n",
    "stopWordList = [word for word in list(stopwords.words('english') ) if word not in ['no', 'not']]\n",
    "# all the data in this dataset is true news, then the target show all equal to 0\n",
    "CBS_NEWS[\"target\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of punctuation that need to be removed\n",
    "punct_removal = list(string.punctuation) + [\"--\", \"---\"]\n",
    "# define the the word pattern\n",
    "word_pattern = r\"(?u)\\b\\w\\w+\\b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if NAN in columns\n",
    "CBS_NEWS[\"Paragraph_text\"].isnull().values.any()\n",
    "\n",
    "#check how many of NAN in columns\n",
    "CBS_NEWS[\"Paragraph_text\"].isnull().sum()\n",
    "# check how many NAN in the whole dataset\n",
    "CBS_NEWS.isnull().values.sum()\n",
    "\n",
    "# fill the NAN with whitespace\n",
    "CBS_NEWS[\"Paragraph_text\"]=CBS_NEWS[\"Paragraph_text\"].fillna(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leonayu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokened_para=[]\n",
    "for i in range(len(CBS_NEWS)):\n",
    "    word_pat = re.compile(word_pattern, flags = re.UNICODE )\n",
    "\n",
    "    CBS_NEWS[\"Paragraph_text\"][i] = \" \".join(word_pat.findall(CBS_NEWS[\"Paragraph_text\"][i])).lower()\n",
    "    \n",
    "    tokens = nlp(CBS_NEWS[\"Paragraph_text\"][i])\n",
    "    #lemmatising tokens \n",
    "    tokens = [t.lemma_.strip() if t.lemma_ != \"-PRON-\" else t.lower_ for t in tokens]\n",
    "    #stopword and punctuation removal\n",
    "    tokens = [t for t in tokens if (t not in stopWordList and t not in punct_removal)]\n",
    "    processed_text = \" \".join(tokens)\n",
    "    tokened_para.append(processed_text) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leonayu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokened_title=[]\n",
    "for i in range(len(CBS_NEWS)):\n",
    "    word_pat = re.compile(word_pattern, flags = re.UNICODE )\n",
    "    CBS_NEWS[\"title\"][i] = \" \".join(word_pat.findall(CBS_NEWS[\"title\"][i])).lower()\n",
    "    tokens = nlp(CBS_NEWS[\"title\"][i])\n",
    "    #lemmatising tokens \n",
    "    tokens = [t.lemma_.strip() if t.lemma_ != \"-PRON-\" else t.lower_ for t in tokens]\n",
    "    #stopword and punctuation removal\n",
    "    tokens = [t for t in tokens if (t not in stopWordList and t not in punct_removal)]\n",
    "    processed_text = \" \".join(tokens)\n",
    "    tokened_title.append(processed_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokened_para_df=pd.DataFrame(tokened_para)\n",
    "tokened_title_df=pd.DataFrame(tokened_title)\n",
    "CBS_NEWS[\"tokened_para\"]=tokened_para_df\n",
    "CBS_NEWS[\"tokened_title\"]=tokened_title_df\n",
    "CBS_NEWS['all_text']=CBS_NEWS[\"tokened_title\"]+CBS_NEWS[\"tokened_para\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       northrop grumman antares rocket boost space st...\n",
       "1       northrop grumman antares rocket boost space st...\n",
       "2       northrop grumman antares rocket boost space st...\n",
       "3       northrop grumman antares rocket boost space st...\n",
       "4       northrop grumman antares rocket boost space st...\n",
       "5       northrop grumman antares rocket boost space st...\n",
       "6       northrop grumman antares rocket boost space st...\n",
       "7       northrop grumman antares rocket boost space st...\n",
       "8       northrop grumman antares rocket boost space st...\n",
       "9       northrop grumman antares rocket boost space st...\n",
       "10      northrop grumman antares rocket boost space st...\n",
       "11      northrop grumman antares rocket boost space st...\n",
       "12      northrop grumman antares rocket boost space st...\n",
       "13      northrop grumman antares rocket boost space st...\n",
       "14      northrop grumman antares rocket boost space st...\n",
       "15      northrop grumman antares rocket boost space st...\n",
       "16      northrop grumman antares rocket boost space st...\n",
       "17      spacex elon musk say put man mars four yearbil...\n",
       "18      spacex elon musk say put man mars four yearsti...\n",
       "19      spacex elon musk say put man mars four yearint...\n",
       "20      spacex elon musk say put man mars four yearfir...\n",
       "21      spacex elon musk say put man mars four yearmus...\n",
       "22      spacex elon musk say put man mars four yearsen...\n",
       "23      spacex elon musk say put man mars four yearwat...\n",
       "24      spacex elon musk say put man mars four yearsun...\n",
       "25      spacex elon musk say put man mars four yearsur...\n",
       "26      northrop grumman antares rocket boost space st...\n",
       "27      northrop grumman antares rocket boost space st...\n",
       "28      northrop grumman antares rocket boost space st...\n",
       "29      northrop grumman antares rocket boost space st...\n",
       "                              ...                        \n",
       "9409    google track movement like notsince 2014 googl...\n",
       "9410    google track movement like notcompany push loc...\n",
       "9411    google track movement like notgoogle also say ...\n",
       "9412    google track movement like notdisable web app ...\n",
       "9413    google track movement like notsean brien yale ...\n",
       "9414    retro future jetsoncbs news time meet jetson m...\n",
       "9415    retro future jetsonshadow iconic water tower h...\n",
       "9416    retro future jetsonfade pencil old storyboard ...\n",
       "9417    retro future jetsoneverything jetson space age...\n",
       "9418    retro future jetsonsuit make us fly colony moo...\n",
       "9419    retro future jetsonjetsonian future year 2062 ...\n",
       "9420    retro future jetsonnovak tell cowan agree jets...\n",
       "9421    retro future jetsonanalyze 24 episode original...\n",
       "9422    retro future jetsonjetson represent retro futu...\n",
       "9423    retro future jetsonanimator william hanna jose...\n",
       "9424       retro future jetsonlot future jetson get right\n",
       "9425    retro future jetsongeorge video phone sure loo...\n",
       "9426    retro future jetsontalk watch would likely goo...\n",
       "9427    retro future jetsongee whiz kind stuff us eat ...\n",
       "9428    retro future jetsonsense though jetsonian betr...\n",
       "9429    retro future jetsonretro futurist mantra novak...\n",
       "9430    retro future jetsonrosie robot often face futu...\n",
       "9431    retro future jetsonregister point rosie take w...\n",
       "9432    retro future jetsonbeloved timeless jetson rem...\n",
       "9433    retro future jetsoneven world fly car jet pack...\n",
       "9434    retro future jetsongadget still good people us...\n",
       "9435    retro future jetsonstill many element jetson f...\n",
       "9436    retro future jetsonmight get fly car yet say c...\n",
       "9437                           retro future jetsonexactly\n",
       "9438                              retro future jetsoninfo\n",
       "Name: all_text, Length: 9439, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CBS_NEWS[[\"tokened_title\",\"tokened_para\",\"target\"]]\n",
    "CBS_NEWS['all_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train headline matrix shape: \t (9439, 407770)\n",
      "Train body matrix shape: \t (9439, 407770)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec = TfidfVectorizer(ngram_range=(1,3))\n",
    "vec.fit(CBS_NEWS.all_text)\n",
    "vocab = vec.vocabulary_\n",
    "    \n",
    "vecH = TfidfVectorizer(ngram_range=(1,3), max_df=0.8, vocabulary=vocab)\n",
    "vecH.fit(CBS_NEWS.tokened_title.unique())\n",
    "    \n",
    "vecB = TfidfVectorizer(ngram_range=(1,3), max_df=0.8, vocabulary=vocab)\n",
    "vecB.fit(CBS_NEWS.tokened_para.unique())\n",
    "    \n",
    "xHTrainTfidf = vecH.transform(CBS_NEWS.tokened_title)\n",
    "print ('Train headline matrix shape: \\t', xHTrainTfidf.shape)\n",
    "    \n",
    "xBTrainTfidf = vecB.transform(CBS_NEWS.tokened_para)\n",
    "print('Train body matrix shape: \\t', xBTrainTfidf.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
